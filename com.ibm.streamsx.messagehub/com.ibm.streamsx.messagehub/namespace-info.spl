/**
 * This SPL namespace contains the operators to connect with an instance of the IBM Event Streams cloud service.
 * These operators are based on the operators of the streamsx.kafka toolkit. It is recommended that users 
 * review the Kafka Toolkit documentation for additional information on supported functionality. 
 * The Kafka Toolkit documentation can be found here: [https://ibmstreams.github.io/streamsx.kafka/|Kafka Toolkit] 
 * 
 * + Setup of the operators
 * 
 * When you create an instance of the IBM Event Streams service, you must also create credentials to use the servcie.
 * These credentials are given in JSON format. This piece of information is required to setup the operators 
 * to connect to the service instance.
 * 
 * Any of the following options can be used to configure the operator for connecting to IBM Cloud.
 *
 * # Save Credentials in Application Configuration Property
 *
 * With this option, users can copy their Event Streams Credentials JSON from the Event Streams service 
 * and store it in an application configuration property named `messagehub.creds`. 
 * When the operator starts, it will look for that property and extract the information needed to connect.
 * The following steps outline how this can be done:
 * 
 * 1. Create an application configuration with the name **messagehub**.
 * 1. Create a property in the messagehub application configuration with the name `messagehub.creds`.
 * 1. The value of the property must be the raw Event Streams Credentials JSON.
 * 1. The operator will automatically look for an application configuration named messagehub and will extract the information needed to connect. Users only need to specify the topic(s) that they wish to consume messages from (set via the topic parameter).
 * 
 * **NOTE 1:** Users can specify a different application configuration name by setting the **appConfigName** parameter.
 * The operator will still look for a property with the name `messagehub.creds` containing the Event Streams Credentials JSON.
 * 
 * **NOTE 2:** Users can add generic Kafka properties, for example `client.id`, to the application configuration.
 * To make the operator use these Kafka properties, the **appConfigName** parameter must be specified even if the default
 * application configuration name `messagehub` is used. Looking at the other way round, when the default
 * application configuration name `messagehub` is used, but *not* specified as **appConfigName** parameter value, 
 * only the service credentials are used from the application config.
 * 
 * 
 * # Save Credentials in a File
 * 
 * With this option, users can copy their Event Streams credentials JSON from the Event Streams service and store it in a
 * file called `messagehub.json`. When the operator starts up it will read the credentials from that file and extract
 * the information needed to connect. The following steps outline how this can be done:
 * 
 * 1. Create a file with the name `messagehub.json` in the <application_directory>/etc/ directory.
 * 1. Paste the Event Streams Credentials JSON into this file and save it.
 * 1. The operator will automatically look for the file <application_directory>/etc/messagehub.json and will extract the information needed to connect. Users only need to specify the topic(s) that they wish to consume messages from (set via the topic parameter).
 * 
 * **NOTE:** Users can use the **messageHubCredentialsFile** parameter to specify a different file containing the Event Streams Credentials in JSON format.
 * 
 * When both, a credentials file and an application configuration is specified, also when the credentials are stored 
 * with the default file name `messagehub.json`, the application configuration is ignored.
 * 
 * 
 * **The following Kafka properties are setup by the operators by default:**
 * 
 * ------------------------------------------------------------------------------------------------------------------------------
 * | property name                         | value                                                                              |
 * |=======================================|====================================================================================|
 * | bootstrap.servers                     | *parsed from the service credentials*                                              |
 * |----------------------------------------------------------------------------------------------------------------------------|
 * | sasl.jaas.config                      | org.apache.kafka.common.security.plain.PlainLoginModule required                   |
 * |                                       |   serviceName="kafka"                                                              |
 * |                                       |   username="*username*"                                                            |
 * |                                       |   password="*password*";                                                           |
 * |                                       |                                                                                    |
 * |                                       | (The *username* and the *password* are extracted from the service credentials.)    |
 * |----------------------------------------------------------------------------------------------------------------------------|
 * | security.protocol                     | SASL_SSL                                                                           |
 * |----------------------------------------------------------------------------------------------------------------------------|
 * | sasl.mechanism                        | PLAIN                                                                              |
 * |----------------------------------------------------------------------------------------------------------------------------|
 * | ssl.protocol                          | TLSv1.2                                                                            |
 * |----------------------------------------------------------------------------------------------------------------------------|
 * | ssl.truststore.type                   | JKS                                                                                |
 * |----------------------------------------------------------------------------------------------------------------------------|
 * | ssl.enabled.protocols                 | TLSv1.2                                                                            |
 * |----------------------------------------------------------------------------------------------------------------------------|
 * | ssl.endpoint.identification.algorithm | HTTPS                                                                              |
 * ------------------------------------------------------------------------------------------------------------------------------
 *
 * 
 * These properties cannot be overwritten by specific Kafka properties provided via properties file or application configuration.
 * They are ignored when specified in a property file or application configuration.
 * 
 * In addition to the properties above, some more properties are setup or adjusted specific for the operators.
 * For reference, review the operator's documentation.
 *
 * 
 * + Tracing Kafka properties
 * 
 * For testing it might desirable to see all effective Kafka Consumer or Producer properties, also those 
 * properties, which have not been setup by application configuration or configuration file.
 * To achieve this, submit the Streams application with **application trace level INFO** or more verbose.
 * Then the properties are traced into the PE trace. Authentication information is hidden.
 *
 * + Tracing Kafka performance metrics
 * 
 * For testing and tuning it might be desirable to see and observe performance metrics of the Kafka 
 * consumer or Kafka Producer client. When the **application trace level** is at **INFO** 
 * (or at a more verbose level), the operators write every two seconds the most 
 * important performance metrics into the trace file. These can be used to tune the 
 * Kafka consumer or producer by applying specific Kafka configs.
 */

namespace com.ibm.streamsx.messagehub;

