<?xml version="1.0" encoding="UTF-8"?>
<info:toolkitInfoModel xmlns:common="http://www.ibm.com/xmlns/prod/streams/spl/common"
 xmlns:info="http://www.ibm.com/xmlns/prod/streams/spl/toolkitInfo">
 <info:identity>
   <info:name>com.ibm.streamsx.messagehub</info:name>
   <info:description>
# Overview

This toolkit integrates IBM Streams with the IBM Event Streams cloud service.
This toolkit is a specialized version of the [https://github.com/IBMStreams/streamsx.kafka|Kafka-Toolkit],
which simplifies the setup for connecting to the cloud service.

# Additional information

+ What's new and what has changed

This is an overview of changes for major and minor version upgrades. For details see the [https://github.com/IBMStreams/streamsx.messagehub/releases|Releases in public Github].

++ What's new in version 2.2.1

This toolkit version is based on the streamsx.kafka bugfix release 2.2.1, which fixes loss of output tuples on the optional status port of the Producer operator when the input port receives a FinalMarker.

++ What's new in version 2.2.0

* The `MessageHubProducer` operator supports an optional output port, configurable via the new **outputErrorsOnly** operator parameter
* Exception handling of the `MessageHubProducer` operator in autonomous region changed. The operator does not abort its PE anymore; it recovers internally instead.
* New custom metrics for the `MessageHubProducer` operator: `nFailedTuples`, `nPendingTuples`, and `nQueueFullPause`

++ What's new in version 2.1.0

This release is based on the streamsx.kafka toolkit version 2.1.0, which has following changes:

* The following consumer and producer configurations are setup by the operators per default:
  * client.dns.lookup = use_all_dns_ips
  * reconnect.backoff.max.ms = 10000 (Kafka's default is 1000)
  * reconnect.backoff.ms = 250 (Kafka's default is 50)
  * retry.backoff.ms = 500 (Kafka's default is 100)
* new optional operator parameter **sslDebug**
* bug fixes, see the release note on [https://github.com/IBMStreams/streamsx.kafka/releases/tag/v2.1.0|Github]

++ What's new in version 2.0.2

* This release is based on the streamsx.kafka bugfix release v2.0.1, which fixes reset failure with checkpoint sequence ID greater than 999.

++ What's new in version 2.0.0

# New Features

* The included Kafka client has been upgraded from version 2.1.1 to version 2.2.1. This is the latest Kafka client recommended by Event Streams.

The toolkit has enhancements for the MessageHubConsumer operator when it is used in an autonomous region (i.e. not part of a consistent region):

* The MessageHubConsumer operator can now participate in a consumer group with **startPosition** parameter values `Beginning`, `End`, and `Time`.
* After re-launch of the PE, the MessageHubConsumer operator does not overwrite the initial fetch offset to what the **startPosition** parameter is.

For the new startPosition handling, the application must include a `JobControlPlane` operator when startPosition is not `Default`.

# Deprecations

The toolkit version 2.x deprecates following items:

* The **messageHubCredentialsFile** parameter. Please use the **credentialsFile** parameter instead
* The default filename `etc/messagehub.json` for service credentials. Please use `etc/eventstreams.json` when you want to use a default filename.
* The default name `messagehub` for an application configuration. Please use `eventstreams` as name for the application configuration when you want to use a default.
* The property name `messagehub.creds` within an application configuration. Please name the property for the Event Streams credentials `eventstreams.creds`.

The deprecated items are still supported by this toolkit version, but may be removed in next major toolkit version 3.0.

# Incompatible changes, which may break existing applications

The behavior of the **MessageHubConsumer** operator changes when

1. The operator is *not* used in a consistent region, and
2. The **startPosition** parameter is used with `Beginning`, `End`, `Time`, or `Offset`.

In all other cases the behavior of the MessageHubConsumer is unchanged. Details of the changes, including sample code, can be found in the 
[https://ibmstreams.github.io/streamsx.messagehub/docs/user/difference_toolkit_v1_vs_v2/|Toolkit documentation on Github].

Previous versions of the MessageHubConsumer operator did *not* enable group management in autonomous regions, with **startPosition** different from `Default`,
even when a group-ID was configured. Since toolkit version 2.0, group management is enabled with all **startPosition** values except `Offset`.

The conditions for a consumer operator to be part of a consumer group
are now identical for consistent and autonomous region:

  1. A group identifier must be specified
  2. The operator must not have a control input port
  3. The **partitions** parameter must not be used

Correct handling of the initial start position requires always a **JobControlPlane** operator in the application graph, also when
consistent region is not used. Without a **JobControlPlane** in the application graph, the Consumer operator will fail to initialize
when **startPosition** is used and is not `Default`.

Since toolkit version 2.0, the **startPosition** has effect only when the consumer operator is initially launched at job submission.
When the consumer's PE is re-launched or when new PEs are launched after changing the width of a parallel region, the fetch position
is *not reset* to what **startPosition** is - in opposite to previous versions. More precisely, the fetch position is now only then reset
for a topic partition, when the consumer has not yet committed offsets for the partition. In all other cases, the consumer
continues fetching at the last committed offset.

++ What's new in version 1.9.3

* This version of the toolkit is based on the [https://github.com/IBMStreams/streamsx.kafka/releases/tag/v1.9.4|streamsx.kafka toolkit version 1.9.4].
* Bug fix: Support for resetToInitialState when checkpointing in an autonomous region is configured
* Changed offset commit failure handling of the consumer when in consistent region: Commit failures do no longer restart the PE

++ What's new in version 1.9.2

* This version of the toolkit is based on the [https://github.com/IBMStreams/streamsx.kafka/releases/tag/v1.9.3|streamsx.kafka toolkit version 1.9.3].
* Bug fix: MessageHubConsumer encounters race condition due to changed behavior of Kafka consumer client 2.1 during partition re-balancing when used in consistent region

++ What's new in version 1.9.1

* improved low memory detection for the consumer when records are queued in the consumer

* No adjustment of **retries** producer configuration to 10, as long as consistent region policy is not `Transactional`. The version 2.1.1 producer's default **retries** config (2,147,483,647) is used instead when not specified.

++ What's new in version 1.9.0

* Upgrade of kafka-clients from version 1.0 to 2.1.1.  For the consumer and producer configuration, please consult the [https://kafka.apache.org/documentation/#consumerconfigs|Consumer Configs] or [https://kafka.apache.org/documentation/#producerconfigs|Producer Configs] section of the Apache Kafka 2.1 documentation.

* The MessageHubProducer can now be flushed after a fixed number of tuples, new optional parameter **flush**.

* Bug fix: MessageHubConsumer can create invalid checkpoint when group management is active. When Kafka's group management is used in a consistent region, the `maxConsecutiveResetAttempts` should be increased (default value is 5).

++ What's new in version 1.8.0

* The MessageHubConsumer can subscribe dynamically to multiple topics by specifying a regular expression for the new **pattern** parameter. Assignment of partitions happens for matching topics at the time of periodic check. When someone creates a new topic with a name that matches, a rebalance will happen almost immediately and the consumers will start consuming from the new topic.

* The control port of the MessageHubConsumer allows assignment with default fetch position. New SPL functions to generate the JSON string for the control port have been added.

* MessageHubConsumer: Offsets can be committed after a *time period*, not only when a tuple count is reached. The new **commitPeriod** operator parameter lets you specify a time period in seconds for committing offsets of submitted tuples.

* MessageHubConsumer: The time policy for offset commit is now the default policy when not in consistent region. The time policy avoids too high commit request rates, which can occur with count based policy and high tuple rates. The default commit interval is 5 seconds.

* The operators can now be configured with a `config checkpoint` clause when used in an autonomous region. The MessageHubProducer operator simply ignores the config instead of throwing an error at compile time. The MessageHubConsumer operator can be configured with operator driven and periodic checkpointing. Checkpointing is in effect when the operator is configured with the optional input port. Then, the operator checkpoints or restores the assigned partitions and resumes fetching at last committed offset.

++ What's new in version 1.7.4

* Bug fix: Avoid tracing the cloud service credentials at INFO level

++ What's new in version 1.7.3

* Bug fix: No default compression for the producer anymore (producer config `compression.type` is Kafka's default).

++ What's new in version 1.7.2

* Bug fix: Reduce trace level for metric dump to `trace`.

++ What's new in version 1.7.1

* operator metrics which got invalid for an operator are flagged with a value of -1, for example the metric for the partition related consumer lag after de-assignment of a partition from a consumer operator
* when not in a consistent region, offsets are committed when partitions are rebalanced within a consumer group. After re-assignment, messages are fetched beginning with the previously committed offsets. The periodic commit controlled by the **commitCount** parameter is reset after rebalance.

++ What's new in version 1.7.0

* New **credentials** operator parameter for raw service credentials in JSON for the operators
* The default value for the **commitCount** parameter of the MessageHubConsumer has changed from 500 to 2000.
* SPL types for standard messages have been added to the toolkit

++ What's new in version 1.6.0

* The MessageHubProducer exposes many performance metrics of the producer client as operator metrics
* The most important producer configs have default values, which result in higher reliability and throughput. These are `retries`, `compression.type`, `linger.ms`, `batch.size`, and `max.in.flight.requests.per.connection`.
* New operator parameter **guaranteeOrdering** for the MessageHubProducer, which guarantees that the sequence in a topic partition is the same as the order of tuples in case of retries.
* Queue control for the MessageHubProducer operator to stabilize the maximum queue time and to avoid timeouts sending records
* The MessageHubConsumer operator exposes some performance metrics of the consumer client as operator metrics, like the lag for each topic partition.

   </info:description>
   <info:version>2.2.1</info:version>
   <info:requiredProductVersion>4.2.0.0</info:requiredProductVersion>
 </info:identity>
 <info:dependencies/>
</info:toolkitInfoModel>
